macro (add_test_target target_subdirectory test_type)



    #
	# set target name
    #
    if (${ARGV1} STREQUAL "unit")
	    set(target_name unittest_${ARGV0})
        set(add_to_test TRUE)
        set(jenkins_file unittest.sh)
        set(testing_dir unit_testing)
        set(max_time 10)
        set(test_driver)
        set(run_options -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})
        set(runstring ${target_name} -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})


    elseif (${ARGV1} STREQUAL "unit_parallel")
	    set(target_name unittest_${ARGV0})
        set(add_to_test TRUE)
        set(jenkins_file unittest.sh)
        set(testing_dir unit_testing)
        set(max_time 10)
        set(test_driver mpirun -np 10)
        set(run_options -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})
        #set(runstring "${MPIRUN_EXECUTABLE} -np 10 ${target_name} -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time}")
        set(runstring mpirun -np 10 ${target_name} -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})

    elseif (${ARGV1} STREQUAL "reg")
        set(target_name regtest_${ARGV0})
        set(jenkins_file regtest.sh)
        set(testing_dir reg_testing)
        set(max_time 1000)
        set(test_driver)
        set(run_options -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})
        set(runstring ${target_name} -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})

    elseif (${ARGV1} STREQUAL "reg_parallel")
        set(target_name regtest_${ARGV0})
        set(jenkins_file regtest.sh)
        set(testing_dir reg_testing)
        set(max_time 1000)
        set(test_driver mpirun -np 10)
        set(run_options -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})
        #set(runstring "${MPIRUN_EXECUTABLE} -np 10 ${target_name} -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time}")
        set(runstring mpirun -np 10 ${target_name} -name ${target_name} -xml ${target_name}.xml -max-timeout-duration ${max_time})

    else()
        message(SEND_ERROR "Invalid test type. Valid types are 'unit' and 'reg'")
    endif()


    #
	# Create folder for parsed test files in the build directory
    #
    file(MAKE_DIRECTORY ${CMAKE_BINARY_DIR}/generated/test)
	file(MAKE_DIRECTORY ${CMAKE_BINARY_DIR}/generated/test/${testing_dir})
	file(MAKE_DIRECTORY ${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0})
	

    #
	# Create input file for registering tests
    #
	file(REMOVE ${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0}/testSuites.inc)
	

    #
	# Include directory created above so the .inc file is available
    #
	include_directories(${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0})
	

    #
	# Include access to pfunit module
    #
	include_directories(${PF_ROOT}/mod)
	



	#-----------------------------------------------------------------------------------------------------------
    #
    #   Loop through each test file, process with pFUnitParser and generate list of output files for compiler
    #   DEPENDS option ensures that if the .pf file is changed, the parser will be called to reprocess the file
    #
    #-----------------------------------------------------------------------------------------------------------
	set(_test_sources)
    foreach (_test ${ARGN})
        #
    	# Get filename without extension (NAME_WE)
        #
    	get_filename_component(filename ${_test} NAME_WE)


        #
        # Get directory associated with filename
        #
        get_filename_component(filedir ${_test} DIRECTORY)
    	

        # 
    	# Test preprocessor command
        #
        add_custom_command(
            OUTPUT ${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0}/${filename}.F90
            COMMAND ${PF_ROOT}/bin/pFUnitParser.py ${CMAKE_SOURCE_DIR}/${filedir}/${filename}.pf ${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0}/${filename}.F90
            DEPENDS ${CMAKE_SOURCE_DIR}/${filedir}/${filename}.pf
            )
        	

        #
        # Accumulate list of test sources to define target
        #
     	set(_test_sources ${_test_sources} ${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0}/${filename}.F90)
     	

        #
     	# Register test in input .inc file for pftest
        #
     	file(APPEND ${CMAKE_BINARY_DIR}/generated/test/${testing_dir}/${ARGV0}/testSuites.inc "ADD_TEST_SUITE(${filename}_suite)\n")

	endforeach()
	
	set_source_files_properties(${PF_ROOT}/include/driver.F90 PROPERTIES GENERATED 1)
	





    #-------------------------------------------------------------------------------------------------------
    #
	#   Define test target and link with pfunit and coredg libraries. These targets are
    #   excluded from the 'all' target and are instead added as dependencies to the 'check' target.
    #
    #   Build test targets using 'make check'
    #
	#-------------------------------------------------------------------------------------------------------
	add_executable(${target_name} EXCLUDE_FROM_ALL ${PF_ROOT}/include/driver.F90 ${_test_sources} )
	target_link_libraries(${target_name} ${PF_ROOT}/lib/libpfunit.a coredg -lstdc++ -lpthread ${MPI_Fortran_LIBRARIES} ${METIS_LIBRARIES})
    	
	set_target_properties(${target_name} PROPERTIES 
                             COMPILE_FLAGS "-DUSE_MPI=True -DBUILD_ROBUST=True ${MPI_Fortran_COMPILE_FLAGS}"
                             LINK_FLAGS    "${MPI_Fortran_LINK_FLAGS}")
	
	
    #
    # Add test executable to the 'check' target. This allows the test to be build with 'make check'
    #
    add_dependencies(check ${target_name} coredg)


	#-------------------------------------------------------------------------------------------------------
    #
	#	Add test that can be run with 'make test' or 'ctest'
    #
    #   Only 'unit' tests are added to the 'make test' target using add_test. They should be much lighter
    #   weight and so should be runable on most machines. 'reg' tests are much more computationally
    #   intensive, and so must be run manually.
	#
    #-------------------------------------------------------------------------------------------------------
    if (${add_to_test})
        #add_test(NAME ${target_name}
        add_test(NAME ${target_subdirectory}
                 WORKING_DIRECTORY ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}
                 COMMAND ${test_driver} $<TARGET_FILE:${target_name}> ${run_options})
    endif()
			 
			 




	#-------------------------------------------------------------------------------------------------------
    #
	#	Add test target to shell script used by Jenkins for executing individual tests
    #
	#-------------------------------------------------------------------------------------------------------
	if (EXISTS "${CMAKE_BINARY_DIR}/bin/${jenkins_file}")
		file(APPEND ${CMAKE_BINARY_DIR}/bin/${jenkins_file} ${runstring}"\n")
	else()
		file(APPEND ${CMAKE_BINARY_DIR}/bin/${jenkins_file} "#!/bin/bash\n")
		file(APPEND ${CMAKE_BINARY_DIR}/bin/${jenkins_file} "cd $WORKSPACE/build/bin\n")
		file(APPEND ${CMAKE_BINARY_DIR}/bin/${jenkins_file} ${runstring}"\n")
	endif()
	






endmacro()
